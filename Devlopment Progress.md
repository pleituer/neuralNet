# Current Version: v0.2.1

## v0.2.1
### Added

- testing for RNNs
- moved `SGRU` to be a child of the `GRU` class
- allowed users to create their own GRU using The `GRU` as a base class

## v0.2 
### Added

- testing for FFNNs
- visualizing for FFNNs
- an new example ([XOR](https://github.com/pleituer/neuralNet/tree/main/examples/XOR))

### Fixed

the visualizer (previously `test` function)

## v0.1 
### Added

- Dense Layer
- Activations (tanh, sigmoid, ReLu, softmax)
- GRUs (a simplistic one with one internal weight and one internal activation function, tanh, and its called `SGRU`)
- LSTM (still in progress of debugging)
- FFNNs
- RNNs
